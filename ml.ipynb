{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cad7f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "from keras import models,layers\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5893e1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt'\n",
    ")\n",
    "text = open(path , encoding= \"utf-8\").read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_indices = {c : i  for i , c in enumerate(chars)}\n",
    "indices_char = {i : c  for i , c in enumerate(chars)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76722bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step  = 3\n",
    "maxlen = 60\n",
    "sentences = []\n",
    "next_chars =  []\n",
    "for i in range(0 , len(text) - maxlen ,step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18794c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences) , maxlen  , len(chars)) , dtype=bool)\n",
    "y = np.zeros((len(sentences) , len(chars)) , dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0069ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i ,t , char_indices[char]] = 1\n",
    "    y[i , char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa77773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('modellolinguistico' , exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy' , patience = 1 ), \n",
    "                  keras.callbacks.ModelCheckpoint(filepath='models_keras.h5', monitor = \"val_loss\" , save_best_only=True),\n",
    "                  keras.callbacks.TensorBoard(log_dir='modellolinguistico',histogram_freq=1 , embeddings_freq=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896e8760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">95,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,353</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m95,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             │         \u001b[38;5;34m7,353\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,169</span> (914.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,169\u001b[0m (914.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,169</span> (914.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,169\u001b[0m (914.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(maxlen  , len(chars))),\n",
    "    layers.LSTM(128 , dropout=0.2 , recurrent_dropout=0.2, return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(len(chars)  , activation='softmax')\n",
    "])\n",
    "optimizers = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'] , optimizer=optimizers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb3f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds , temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(np.clip(preds , 1e-8,1)) / temperature\n",
    "    exp_pred = np.exp(preds)\n",
    "    preds = exp_pred / np.sum(exp_pred)\n",
    "    probas = np.random.multinomial(1 , preds , 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725565c1",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 105ms/step - accuracy: 0.2732 - loss: 2.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\salva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: accuracy,loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "c:\\Users\\salva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:209: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----diversity: 0.2\n",
      "-----Sentence: t of the most be like of the something the gare have been ev\n",
      "soporific\n",
      "appliances--and that \"virtue,\" in my opinion, has ery he diser and the fen and for the fene the can and his a man the fare the senser and sensing and the fine and and the preally and the prade and the every and the belight that the beling and the proper of the fare the man and the for the preser the bele of the preally the hister of the ending and the can the fare and will sen and the delief and such of the belight that the prefer the preser and -----diversity: 0.5\n",
      "-----Sentence: lief and such of the belight that the prefer the preser and \n",
      "soporific\n",
      "appliances--and that \"virtue,\" in my opinion, has disprension and in chase that the delality of the preed that the ord that our be the dast and the pread of the mast that as san and from which all proate and the world for the erived to at orleine and the lang for the yen and digre and dight of the wisen and un and for a all from will more propes of a dadething and from and deer of here an every be refure the mere or every the man of prople and be-----diversity: 1.0\n",
      "-----Sentence: n every be refure the mere or every the man of prople and be\n",
      "soporific\n",
      "appliances--and that \"virtue,\" in my opinion, has  that certy tind bevittres of wise us ver parpon fan all is rad of his inter  fas detinct, ald evols fivile, shill to which of \"chagine or impans thing, the mame enlowmous indanms wall canse! and\n",
      "will beywer moralle of strut i stirt, to cancilvy yid the prosting hadse extrasire af a 1heint men and in in himselfing of he meaknly is it as concebace and angifice hare his innigheu selfer--that in belo-----diversity: 1.2\n",
      "-----Sentence: oncebace and angifice hare his innigheu selfer--that in belo\n",
      "soporific\n",
      "appliances--and that \"virtue,\" in my opinion, has og ever, ongied, a that\n",
      "socarlies. ull xen incitience, and in whrich but mape eder; ere buth, on a gundice, is min unle cremar, in out jutuu\n",
      "be this seetied with beleavedre that day\n",
      "\n",
      "led, he ebeniviclals, theme--\"nantidad beflee revened jeoner, bo abemals inef du\"l, dere. everdut\n",
      "yidodady doseds af a benape\n",
      "yoder instine bub the beown, that   dariat wen wall the cendicugh may,\" time alr for\n",
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 98ms/step - accuracy: 0.4436 - loss: 1.8613\n",
      "-----diversity: 0.2\n",
      "-----Sentence: at   dariat wen wall the cendicugh may,\" time alr for\n",
      "wime n\n",
      "he day,\n",
      "result, through their novelty, in a movement throughot the contempless of the contempless of the part of the sense of the can the can of the contemple and the perhaps as a moral and the spirit of the sense of the generated to the sense of the conterpathy and regards of the conscience of the contemplition of the causes of the canters of the present in the contempless of the contemple of the can is the contemplition of the contemplition of the contem-----diversity: 0.5\n",
      "-----Sentence:  can is the contemplition of the contemplition of the contem\n",
      "he day,\n",
      "result, through their novelty, in a movement throughplises, self-canding and more of the conception and manked, the expection of the edaparispuled in the conderstand which of so relation and himself as even of the he last in the when the persons like for the faintion of him, in perhaps for the clank as his ving of the ganding and of the exparing this fact the centement of the will to he so the vill of the\n",
      "light of consciently that when should of th-----diversity: 1.0\n",
      "-----Sentence:  the vill of the\n",
      "light of consciently that when should of th\n",
      "he day,\n",
      "result, through their novelty, in a movement throughe motition, the langilagity for the purwasiin themself again beconsthing, and themselves. and lakers. pyith puryices with oscend of liftces of rangual to and phistiding of\n",
      "conthing then a schologs\n",
      "herefadn inclentnuality of onvequentience sconthal saccish aid to man\n",
      "liferour\n",
      "foodsguce, with kiners for one sparey, from the viltry which \"gensiunce, it is perhaps\n",
      "bie. hims arce of as onservelw have n-----diversity: 1.2\n",
      "-----Sentence: nsiunce, it is perhaps\n",
      "bie. hims arce of as onservelw have n\n",
      "he day,\n",
      "result, through their novelty, in a movement throughot readvidials manks us as begerders: therqle-cattew!\"\n",
      "\"qutifiving time of which scounty,\n",
      "without is he would coniety wisherouls,\n",
      "that moght-spoptes of\n",
      "how resteging to\n",
      "all that chusariceable\n",
      "wish or shord relilitions, but fature is eeedy-contempty whiching acm-for the negreg tf dil,--its \"gright as which, is a very\" hesics ethysh-it is not invil-upun,-\"the=vantyds,s, hepon.\n",
      "\u001b[1m1565/1565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 92ms/step - accuracy: 0.4867 - loss: 1.7067\n",
      "-----diversity: 0.2\n",
      "-----Sentence: ot invil-upun,-\"the=vantyds,s, hepon.\n",
      "canary havest vafner h\n",
      "has, perhaps,\n",
      "nothing else to share--in which renunciation aave the same the faither and the more such a more the such a more the self-considernally and the sense of the same the same the self-consideration of the sense the self-assinction, the same the fall the self-considernally seems and the same the self-as the such a prompt of the same the self-such a men and the same the same the more the self-same the such a perhaps any the subting of the same the s-----diversity: 0.5\n",
      "-----Sentence: lf-same the such a perhaps any the subting of the same the s\n",
      "has, perhaps,\n",
      "nothing else to share--in which renunciation aelf-been the more the morality in the something itself. that is suffering and experience in all the proment in the more hered the sain of the great has must of the self--and the soul,\n",
      "and strians of the far delight and the latter the inventions is a subtrusion of the morally sense are the such a man man more an angurence who relations, and in the formand the inflution of such the conduction of cau-----diversity: 1.0\n",
      "-----Sentence: d in the formand the inflution of such the conduction of cau\n",
      "has, perhaps,\n",
      "nothing else to share--in which renunciation ar man happ inplendssing\n",
      "uning\n",
      "equated lat in stmess afrramental eemorally agot of the while as the planwon at the percams we clecensines at the leads of spiritsafre as though humanle, of\n",
      "the tilation, the trund, instincts the with the men when coulse\n",
      "are,\n",
      "therefered promptys and\n",
      "such i somewherefided and here agaret\n",
      "the venemal luted aschirate) in whole we intesses horely\n",
      "traconed\". hoew. this lus-----diversity: 1.2\n",
      "-----Sentence: irate) in whole we intesses horely\n",
      "traconed\". hoew. this lus\n",
      "has, perhaps,\n",
      "nothing else to share--in which renunciation atrentions of visually smr: frostly; the voluctue9ress quinationativet,\n",
      "such fangulasn, \"pownle\n",
      "of\n",
      "the gestanding of christic). subting bot oet\n",
      "against herry, recontrincts makes the imperians accemmng out it is almont\n",
      "dupter divinle unecods ocicansly. themself waydhiate(--\n",
      "kenamerty. rutury when,\n",
      "as\n",
      "not the iding acchieng. sensy of icide'th\n",
      "\u001b[1m  67/1565\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 76ms/step - accuracy: 0.5197 - loss: 1.6211"
     ]
    }
   ],
   "source": [
    "for epoch in range(1 , 61):\n",
    "    model.fit(x,  y , batch_size=128 , epochs=1 , callbacks=callbacks_list)\n",
    "    start = random.randint(0 , len(text) - maxlen - 1)\n",
    "    for diversity in [0.2 , 0.5 , 1.0 , 1.2]:\n",
    "        print(f\"-----diversity: {diversity}\")\n",
    "        generated = ''\n",
    "        generated += text[start :start + maxlen]\n",
    "        print(\"-----Sentence: {}\".format(sentence))\n",
    "        sys.stdout.write(generated)\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1 , maxlen , len(chars)))\n",
    "            for t , char in enumerate(sentence):\n",
    "                x_pred[0 , t, char_indices[char]] = 1\n",
    "            preds = model.predict(x_pred , verbose=0)[0]\n",
    "            next_index = sample(preds , diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            generated += next_char\n",
    "            sentence   = sentence[1:] + next_char\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
